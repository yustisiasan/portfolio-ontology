{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing adalah tahap mempersiapkan data sebelum di proses, dimana pada tahap preprocessing ini terdapat beberapa poses yaitu. <br>\n",
    "<ul>\n",
    "\t<li>casefold</li>\n",
    "\t<li>tokenisasi</li>\n",
    "\t<li>stopword removal</li>\n",
    "\t<li>remove symbol dan character</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pada tahap ini dibutuhkan beberapa library yang dibutuhkan yaitu.\n",
    "<ul>\n",
    "\t<li><b>nltk.tokenize</b>: berfungsi untuk membuat kalimat tweet menjadi token</li>\n",
    "\t<li><b>Regular Expresion (re)</b> : untuk menghapus karakter dan simbol yang tidak dibutuhkan</li>\n",
    "\t<li><b>nltk.corpus </b> : untuk mendapatkan daftar kata yang tidak memiliki makna</li>\n",
    "\t<li><b>pandas</b> : untuk memproses data yang berhubungan dengan csv</li>\n",
    "\t<li><b>numpy</b> : untuk memproses data yang berhubungan dengan array</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('indonesian'))\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casefold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk merubah kalimat tweet menjadi lowercase (huruf kecil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casefold(str):\n",
    "    return str.casefold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merubah kalimat tweet menjadi sebuah token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenisasi(str):\n",
    "    return tknzr.tokenize(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk menghapus kata yang tidak memiliki makna. berikut contoh beberapa kata yang terdapat dalam stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['semasih', 'asal', 'mana', 'lewat', 'kami', 'nah', 'menghendaki', 'sementara', 'masih', 'tiba-tiba', 'belakangan', 'bermacam', 'sedemikian', 'sedikit', 'walau', 'lanjut', 'sebab', 'sama-sama', 'sehingga', 'yakni', 'setibanya', 'semampu', 'kelamaan', 'terakhir', 'berakhirnya', 'ditanyai', 'datang', 'katanya', 'pertama-tama', 'digunakan']\n"
     ]
    }
   ],
   "source": [
    "data = list(set(stopWords))\n",
    "print(data[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_removal(token):\n",
    "    result = []\n",
    "    for i in range(len(token)):\n",
    "        if token[i] not in stopWords: #mengecek apakah token tidak ada dalam stopword\n",
    "            result.append(token[i]) #menyimpan dalam result untuk d return\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pada fungsi ini dilakukan tahap penghapusan.<br>\n",
    "<ul>\n",
    "\t<li>mention dan hastag</li>\n",
    "\t<li>Link</li>\n",
    "\t<li>Symbol</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_symbol_removal(token):\n",
    "    new_token = []\n",
    "    for t in token:\n",
    "        if t[:1] != \"@\" and t[:1] != \"#\": # mengecek token yang tidak diawali dengan @ dan #\n",
    "            url_removed = re.sub(r\"http\\S+\", \"\", t) #mengubah http menjadi \"\" agar terhapus\n",
    "            emoji_removed = re.sub(r\"([\\\\x][a-z0-9A-Z]+)\",\"\",url_removed)\n",
    "            symbol_removed = re.sub(r\"[^\\w]\", \"\", emoji_removed)\n",
    "            if symbol_removed != '' and symbol_removed != '\\xF0': # mengecek agar tidak ada token yang kosong nantinya\n",
    "                new_token.append(symbol_removed)\n",
    "    return new_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pada tahap ini fungsi di atas digabung menjadi satu agar mudah di panggil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(string):\n",
    "    string = string[2:-1] # string dimulai dari 2 sampai -1 karena data sebelumnya telah di encode\n",
    "    a = casefold(string) # merubah ke huruf kecil\n",
    "    a = tokenisasi(a) # membuat token\n",
    "    a = stopword_removal(a) # menghapus kata yang tidak penting\n",
    "    a = url_symbol_removal(a) # menghapus simbol dan link\n",
    "    a = ' '.join(a) # membuat array menjadi string\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pada tahap ini data yang telah di training atau diberi label akan di baca menggunakan pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_labeled2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "berikut sample data dari data training<br>\n",
    "<ul>\n",
    "\t<li>1 = positif</li>\n",
    "\t<li>0 = negatif</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Tweet</th>\n",
       "      <th>ID User</th>\n",
       "      <th>Screen Name</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'1127833624202465280'</td>\n",
       "      <td>b'859712550799200257'</td>\n",
       "      <td>sartika_sukardi</td>\n",
       "      <td>b'Pasangan @jokowi mengalahkan Om Giant dan Om...</td>\n",
       "      <td>5/13/2019 7:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'1127831284674322433'</td>\n",
       "      <td>b'1120359729090318336'</td>\n",
       "      <td>sakuratoto01</td>\n",
       "      <td>b'@Kemenperin_RI nahh .. kita kerja nyata buka...</td>\n",
       "      <td>5/13/2019 7:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'1127827783399366657'</td>\n",
       "      <td>b'1051602844510384128'</td>\n",
       "      <td>ikutjokowimaruf</td>\n",
       "      <td>b'Nyatanya di Era Kepemimpinan Jokowi Inflasi ...</td>\n",
       "      <td>5/13/2019 6:47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'1127827677572767744'</td>\n",
       "      <td>b'1033393409887678466'</td>\n",
       "      <td>hamburadulw2</td>\n",
       "      <td>b'Dia yang menciptakan mata nyamuk adalah Dzat...</td>\n",
       "      <td>5/13/2019 6:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'1127827675068821504'</td>\n",
       "      <td>b'1031835377433108480'</td>\n",
       "      <td>dwiharyanto26</td>\n",
       "      <td>b'Jagalah dengan baik orang \\xe2\\x80\\x93 orang...</td>\n",
       "      <td>5/13/2019 6:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'1127827674322178048'</td>\n",
       "      <td>b'1031831060491816960'</td>\n",
       "      <td>NurCahyo_404</td>\n",
       "      <td>b'Cukup diam, ketika ucapan tak lagi memiliki ...</td>\n",
       "      <td>5/13/2019 6:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b'1127827673537888258'</td>\n",
       "      <td>b'1031818445673787392'</td>\n",
       "      <td>PeciPecinta</td>\n",
       "      <td>b'Jangan berputus asa, tuhan selalu setia bers...</td>\n",
       "      <td>5/13/2019 6:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'1127827645557690368'</td>\n",
       "      <td>b'2355116808'</td>\n",
       "      <td>merahputih_id_</td>\n",
       "      <td>b'Tak perlulah takut akan jatuh cinta, karena ...</td>\n",
       "      <td>5/13/2019 6:47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'1127827582328528896'</td>\n",
       "      <td>b'1027146513879715841'</td>\n",
       "      <td>Zahrazarra1</td>\n",
       "      <td>b'Musuh Jokowi akan TETAP serang Jokowi siapap...</td>\n",
       "      <td>5/13/2019 6:47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b'1127827578390175744'</td>\n",
       "      <td>b'1027149863824150529'</td>\n",
       "      <td>katon_kara</td>\n",
       "      <td>b'Kalau mau mendukung kubu sebelah ya silahkan...</td>\n",
       "      <td>5/13/2019 6:47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID Tweet                 ID User      Screen Name  \\\n",
       "0  b'1127833624202465280'   b'859712550799200257'  sartika_sukardi   \n",
       "1  b'1127831284674322433'  b'1120359729090318336'     sakuratoto01   \n",
       "2  b'1127827783399366657'  b'1051602844510384128'  ikutjokowimaruf   \n",
       "3  b'1127827677572767744'  b'1033393409887678466'     hamburadulw2   \n",
       "4  b'1127827675068821504'  b'1031835377433108480'    dwiharyanto26   \n",
       "5  b'1127827674322178048'  b'1031831060491816960'     NurCahyo_404   \n",
       "6  b'1127827673537888258'  b'1031818445673787392'      PeciPecinta   \n",
       "7  b'1127827645557690368'           b'2355116808'   merahputih_id_   \n",
       "8  b'1127827582328528896'  b'1027146513879715841'      Zahrazarra1   \n",
       "9  b'1127827578390175744'  b'1027149863824150529'       katon_kara   \n",
       "\n",
       "                                               Tweet       Timestamp  Label  \n",
       "0  b'Pasangan @jokowi mengalahkan Om Giant dan Om...  5/13/2019 7:11      1  \n",
       "1  b'@Kemenperin_RI nahh .. kita kerja nyata buka...  5/13/2019 7:01      0  \n",
       "2  b'Nyatanya di Era Kepemimpinan Jokowi Inflasi ...  5/13/2019 6:47      1  \n",
       "3  b'Dia yang menciptakan mata nyamuk adalah Dzat...  5/13/2019 6:47      0  \n",
       "4  b'Jagalah dengan baik orang \\xe2\\x80\\x93 orang...  5/13/2019 6:47      0  \n",
       "5  b'Cukup diam, ketika ucapan tak lagi memiliki ...  5/13/2019 6:47      0  \n",
       "6  b'Jangan berputus asa, tuhan selalu setia bers...  5/13/2019 6:47      0  \n",
       "7  b'Tak perlulah takut akan jatuh cinta, karena ...  5/13/2019 6:47      0  \n",
       "8  b'Musuh Jokowi akan TETAP serang Jokowi siapap...  5/13/2019 6:47      1  \n",
       "9  b'Kalau mau mendukung kubu sebelah ya silahkan...  5/13/2019 6:47      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = data[\"Tweet\"]\n",
    "label = data[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setiap tweet akan looping dan di klasifikasikan menjadi kelas Positif atau Negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(tweets)):\n",
    "    pre = preprocessing(tweets[i]) if preprocessing(tweets[i]) != \"\" else \"bagus\" if label[i] == 1 else \"payah\"\n",
    "    result.append({'Text' : pre,'Label' : label[i]})\n",
    "df = pd.DataFrame(result) # membuat data frame dari result\n",
    "df.to_csv('preprocessing result.csv', index=False, header='column_names') # mengubah dataframe ke csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data hasil processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=pd.read_csv('preprocessing result.csv')\n",
    "#pd.read_csv('preprocessing result.csv')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "#stemming process\n",
    "#sentence = ['lowercased']\n",
    "\n",
    "file['stemmed'] = file[\"Text\"].apply(lambda s: stemmer.stem(s))\n",
    "file\n",
    "df = pd.DataFrame(file) # membuat data frame dari result\n",
    "df.to_csv('hasil stemming.csv', index=False, header='column_names') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
